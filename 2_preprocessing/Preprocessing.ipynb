{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from tqdm import tqdm\n",
    "from nlp_id.tokenizer import Tokenizer\n",
    "from nlp_id.lemmatizer import Lemmatizer \n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory, StopWordRemover, ArrayDictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          &                                          dan\n",
      "0         +                                       tambah\n",
      "1         /                                         atau\n",
      "2     22nya                                   dua-duanya\n",
      "3        3m  mencuci tangan memakai masker menjaga jarak\n",
      "4       7an                                       tujuan\n",
      "...     ...                                          ...\n",
      "5593  yyaaa                                           ya\n",
      "5594      z                                         saja\n",
      "5595     za                                         saja\n",
      "5596   zama                                        zaman\n",
      "5597   zonk                                        bodoh\n",
      "\n",
      "[5598 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Import kamus bahasa slang\n",
    "slang_dict = pd.read_csv('https://raw.githubusercontent.com/muhammadariffaizin/sistem-temu-kembali-informasi/master/list/slang.txt', delimiter = \";\")\n",
    "dict_slang = dict(slang_dict.values)\n",
    "print (slang_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3444: DtypeWarning: Columns (9) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(67950, 17)\n",
      "(1209, 17)\n"
     ]
    }
   ],
   "source": [
    "bungs = pd.read_csv(\"https://raw.githubusercontent.com/muhammadariffaizin/sistem-temu-kembali-informasi/master/data/bungs.csv\")\n",
    "print(bungs.shape)\n",
    "\n",
    "catatanali07 = pd.read_csv(\"https://raw.githubusercontent.com/muhammadariffaizin/sistem-temu-kembali-informasi/master/data/catatanali07.csv\")\n",
    "print(catatanali07.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = Lemmatizer()\n",
    "tokenizer = Tokenizer()\n",
    "stop_factory = StopWordRemoverFactory()\n",
    "\n",
    "data_stopword = stop_factory.get_stop_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(s):\n",
    "    s = re.sub(r'(\\\\x[0-9a-fA-Z]{2})', '', s)\n",
    "  #Remove URL\n",
    "    s = re.sub(r'https?://\\S+|www\\.\\S+', \" \", s)\n",
    "  #Remove Mentions\n",
    "    s = re.sub(r'@\\w+',' ',s)\n",
    "  #Remove Punctuation\n",
    "    s= re.sub(r'[^\\w\\s\\d]',' ',s)\n",
    "  #Remove Digits\n",
    "    s = re.sub(r'\\d+', ' ', s)\n",
    "  #Remove HTML tags\n",
    "    s = re.sub('r<.*?>',' ', s)\n",
    "  #Remove Hastags\n",
    "    s = re.sub(r'#\\w+', ' ', s)\n",
    "    s = re.sub(r'[^a-zA-Z]', ' ', s) # remove symbol dan angka\n",
    "    hasil=[]\n",
    "    word_token = tokenizer.tokenize(s) #tokenisasi\n",
    "    for word in word_token:\n",
    "        word = word.strip().lower()   #case folding\n",
    "        if word in dict_slang:\n",
    "            word = dict_slang[word]\n",
    "        if len(word) > 3:\n",
    "          #word = lemmatizer.lemmatize(word) #lemmatization\n",
    "          hasil.append(word)\n",
    "        else:\n",
    "            continue\n",
    "    result_sentence = \" \".join(hasil).strip() #penggabungan kata hasil pre prosesing\n",
    "    #print(result_sentence)\n",
    "    return result_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67950/67950 [00:23<00:00, 2836.19it/s]\n",
      "100%|██████████| 1209/1209 [00:00<00:00, 3099.86it/s]\n"
     ]
    }
   ],
   "source": [
    "data_raw_bungs = bungs\n",
    "data_raw_catatanali07 = catatanali07\n",
    "\n",
    "#Melakukan Proses Pre Prosesing pada Kolom text Dataset \n",
    "result_preprocess_bungs = []\n",
    "for i, row in tqdm(data_raw_bungs.iterrows(), total=data_raw_bungs.shape[0]):\n",
    "  result_preprocess_bungs.append(preprocess(row['Tweet Text']))\n",
    "\n",
    "#Melakukan Proses Pre Prosesing pada Kolom text Dataset \n",
    "result_preprocess_catatanali07 = []\n",
    "for i, row in tqdm(data_raw_catatanali07.iterrows(), total=data_raw_catatanali07.shape[0]):\n",
    "  result_preprocess_catatanali07.append(preprocess(row['Tweet Text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bungs :  (67950, 18)\n",
      "Catatanali07 :  (1209, 18)\n",
      "Bungs Preprocessed :  (48569, 18)\n",
      "Catatanali07 Preprocessed :  (734, 18)\n"
     ]
    }
   ],
   "source": [
    "data_raw_bungs['text_clean'] = result_preprocess_bungs\n",
    "data_raw_catatanali07['text_clean'] = result_preprocess_catatanali07\n",
    "\n",
    "print(\"Bungs : \", data_raw_bungs.shape)\n",
    "print(\"Catatanali07 : \", data_raw_catatanali07.shape)\n",
    "data_raw_bungs = data_raw_bungs[(data_raw_bungs['text_clean'].str.split(\" \").str.len() > 2)]\n",
    "data_raw_catatanali07 = data_raw_catatanali07[(data_raw_catatanali07['text_clean'].str.split(\" \").str.len() > 2)]\n",
    "\n",
    "print(\"Bungs Preprocessed : \", data_raw_bungs.shape)\n",
    "print(\"Catatanali07 Preprocessed : \", data_raw_catatanali07.shape)\n",
    "\n",
    "data_raw_bungs.to_csv(\"bungs_preprocessed.csv\")\n",
    "data_raw_catatanali07.to_csv(\"catatanali07_preprocessed.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
